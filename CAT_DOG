{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9744968,"sourceType":"datasetVersion","datasetId":5965533}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T14:53:43.422099Z","iopub.execute_input":"2024-10-28T14:53:43.422426Z","iopub.status.idle":"2024-10-28T14:53:45.371483Z","shell.execute_reply.started":"2024-10-28T14:53:43.422398Z","shell.execute_reply":"2024-10-28T14:53:45.370651Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/test-data/cat.jpg\n/kaggle/input/test-data/dog.jpg\n/kaggle/input/test-data/koala.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"import timm","metadata":{"execution":{"iopub.status.busy":"2024-10-28T14:53:47.427039Z","iopub.execute_input":"2024-10-28T14:53:47.427442Z","iopub.status.idle":"2024-10-28T14:54:12.267893Z","shell.execute_reply.started":"2024-10-28T14:53:47.427411Z","shell.execute_reply":"2024-10-28T14:54:12.267156Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":"timm.list_models('convnext*')","metadata":{"execution":{"iopub.status.busy":"2024-10-28T14:54:26.827309Z","iopub.execute_input":"2024-10-28T14:54:26.828146Z","iopub.status.idle":"2024-10-28T14:54:26.833485Z","shell.execute_reply.started":"2024-10-28T14:54:26.828109Z","shell.execute_reply":"2024-10-28T14:54:26.832821Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['convnext_atto',\n 'convnext_atto_ols',\n 'convnext_base',\n 'convnext_femto',\n 'convnext_femto_ols',\n 'convnext_large',\n 'convnext_large_mlp',\n 'convnext_nano',\n 'convnext_nano_ols',\n 'convnext_pico',\n 'convnext_pico_ols',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge',\n 'convnext_xxlarge',\n 'convnextv2_atto',\n 'convnextv2_base',\n 'convnextv2_femto',\n 'convnextv2_huge',\n 'convnextv2_large',\n 'convnextv2_nano',\n 'convnextv2_pico',\n 'convnextv2_small',\n 'convnextv2_tiny']"},"metadata":{}}]},{"cell_type":"code","source":"!pip install fastai","metadata":{"execution":{"iopub.status.busy":"2024-10-28T15:08:40.090944Z","iopub.execute_input":"2024-10-28T15:08:40.091345Z","iopub.status.idle":"2024-10-28T15:08:52.820720Z","shell.execute_reply.started":"2024-10-28T15:08:40.091305Z","shell.execute_reply":"2024-10-28T15:08:52.819570Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: fastai in /opt/conda/lib/python3.10/site-packages (2.7.17)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai) (24.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fastai) (21.3)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai) (0.0.7)\nRequirement already satisfied: fastcore<1.8,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai) (1.7.10)\nRequirement already satisfied: torchvision>=0.11 in /opt/conda/lib/python3.10/site-packages (from fastai) (0.19.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from fastai) (3.7.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from fastai) (2.2.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fastai) (2.32.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from fastai) (6.0.2)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai) (1.0.3)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from fastai) (10.3.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fastai) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from fastai) (1.14.1)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai) (3.7.6)\nRequirement already satisfied: torch<2.5,>=1.10 in /opt/conda/lib/python3.10/site-packages (from fastai) (2.4.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (4.66.4)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.9.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (70.0.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.4.1)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->fastai) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (3.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (2024.6.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (1.4.5)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->fastai) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->fastai) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastai) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastai) (3.5.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.23.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<4->fastai) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<2.5,>=1.10->fastai) (1.3.0)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from fastai.vision.all import *\npath = untar_data(URLs.PETS)/'images'\ndef is_cat(x):\n    return x[0].isupper()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T15:08:52.822572Z","iopub.execute_input":"2024-10-28T15:08:52.822860Z","iopub.status.idle":"2024-10-28T15:09:24.008027Z","shell.execute_reply.started":"2024-10-28T15:08:52.822827Z","shell.execute_reply":"2024-10-28T15:09:24.007246Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='811712512' class='' max='811706944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [811712512/811706944 00:13&lt;00:00]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"dls = ImageDataLoaders.from_name_func(\n    path, get_image_files(path), valid_pct = 0.2, seed = 42,\n    label_func = is_cat, item_tfms = Resize(224)\n)\nprint(\"Images Loaded\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T15:09:24.009611Z","iopub.execute_input":"2024-10-28T15:09:24.009914Z","iopub.status.idle":"2024-10-28T15:09:25.058403Z","shell.execute_reply.started":"2024-10-28T15:09:24.009882Z","shell.execute_reply":"2024-10-28T15:09:25.057424Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Images Loaded\n","output_type":"stream"}]},{"cell_type":"code","source":"learn_convnext = vision_learner(dls, 'convnextv2_femto', metrics = error_rate).to_fp16()\nlearn_convnext.fine_tune(1)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T15:09:42.640561Z","iopub.execute_input":"2024-10-28T15:09:42.641303Z","iopub.status.idle":"2024-10-28T15:10:34.391461Z","shell.execute_reply.started":"2024-10-28T15:09:42.641263Z","shell.execute_reply":"2024-10-28T15:10:34.390463Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.136676</td>\n      <td>0.015742</td>\n      <td>0.005413</td>\n      <td>00:24</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.015824</td>\n      <td>0.006298</td>\n      <td>0.003383</td>\n      <td>00:27</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"m = learn_convnext.model\nm","metadata":{"execution":{"iopub.status.busy":"2024-10-28T15:10:39.176770Z","iopub.execute_input":"2024-10-28T15:10:39.177588Z","iopub.status.idle":"2024-10-28T15:10:39.187027Z","shell.execute_reply.started":"2024-10-28T15:10:39.177544Z","shell.execute_reply":"2024-10-28T15:10:39.186129Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): TimmBody(\n    (model): ConvNeXt(\n      (stem): Sequential(\n        (0): Conv2d(3, 48, kernel_size=(4, 4), stride=(4, 4))\n        (1): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n      )\n      (stages): Sequential(\n        (0): ConvNeXtStage(\n          (downsample): Identity()\n          (blocks): Sequential(\n            (0): ConvNeXtBlock(\n              (conv_dw): Conv2d(48, 48, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=48)\n              (norm): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n            (1): ConvNeXtBlock(\n              (conv_dw): Conv2d(48, 48, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=48)\n              (norm): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n          )\n        )\n        (1): ConvNeXtStage(\n          (downsample): Sequential(\n            (0): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n            (1): Conv2d(48, 96, kernel_size=(2, 2), stride=(2, 2))\n          )\n          (blocks): Sequential(\n            (0): ConvNeXtBlock(\n              (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n              (norm): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n            (1): ConvNeXtBlock(\n              (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n              (norm): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n          )\n        )\n        (2): ConvNeXtStage(\n          (downsample): Sequential(\n            (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n            (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n          )\n          (blocks): Sequential(\n            (0): ConvNeXtBlock(\n              (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n              (norm): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n            (1): ConvNeXtBlock(\n              (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n              (norm): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n            (2): ConvNeXtBlock(\n              (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n              (norm): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n            (3): ConvNeXtBlock(\n              (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n              (norm): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n            (4): ConvNeXtBlock(\n              (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n              (norm): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n            (5): ConvNeXtBlock(\n              (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n              (norm): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n          )\n        )\n        (3): ConvNeXtStage(\n          (downsample): Sequential(\n            (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n            (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n          )\n          (blocks): Sequential(\n            (0): ConvNeXtBlock(\n              (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n              (norm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n            (1): ConvNeXtBlock(\n              (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n              (norm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n              (mlp): GlobalResponseNormMlp(\n                (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n                (act): GELU()\n                (drop1): Dropout(p=0.0, inplace=False)\n                (grn): GlobalResponseNorm()\n                (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n                (drop2): Dropout(p=0.0, inplace=False)\n              )\n              (shortcut): Identity()\n              (drop_path): Identity()\n            )\n          )\n        )\n      )\n      (norm_pre): Identity()\n      (head): NormMlpClassifierHead(\n        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n        (norm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n        (flatten): Flatten(start_dim=1, end_dim=-1)\n        (pre_logits): Identity()\n        (drop): Dropout(p=0.0, inplace=False)\n        (fc): Identity()\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=768, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"learn_convnext.predict(\"/kaggle/input/test-data/cat.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.learner import Path\nlearn_convnext.export(Path('/kaggle/working/model_convnext_fine_tuned.pkl'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn_resnet = vision_learner(dls, resnet34, metrics= error_rate)\nprint(\"Model Initialized\")\nlearn_resnet.fine_tune(1)\nprint(\"Training Complete\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T15:11:51.480668Z","iopub.execute_input":"2024-10-28T15:11:51.481574Z","iopub.status.idle":"2024-10-28T15:12:51.948688Z","shell.execute_reply.started":"2024-10-28T15:11:51.481531Z","shell.execute_reply":"2024-10-28T15:12:51.947618Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00<00:00, 193MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Model Initialized\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.153702</td>\n      <td>0.022610</td>\n      <td>0.007442</td>\n      <td>00:25</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.057377</td>\n      <td>0.027627</td>\n      <td>0.006089</td>\n      <td>00:33</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Training Complete\n","output_type":"stream"}]},{"cell_type":"code","source":"m_res = learn_resnet.model\nm_res","metadata":{"execution":{"iopub.status.busy":"2024-10-28T15:12:51.950536Z","iopub.execute_input":"2024-10-28T15:12:51.950868Z","iopub.status.idle":"2024-10-28T15:12:51.959203Z","shell.execute_reply.started":"2024-10-28T15:12:51.950833Z","shell.execute_reply":"2024-10-28T15:12:51.958113Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"learn_resnet.export(Path('/kaggle/working/model_resnet_fine_tuned.pkl'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}